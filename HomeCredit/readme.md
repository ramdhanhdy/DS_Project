# Home Credit Default Risk

#### -- Project Status: [Active]

## Project Intro/Objective
The purpose of this project is to develop a machine learning model for predicting whether a client will have payment difficulties or not based on the dataset from Home Credit, a service dedicated to provided lines of credit (loans) to the unbanked population. 

### Methods Used
* Data Preprocessing
* Feature Selection
* Machine Learning
* Hyperparameter Tuning
* Model Evaluation

### Technologies
* Python
* Jupyter Notebook
* Scikit-Learn
* XGBoost
* CatBoost
* Pandas
* Hyperopt

## Project Description
In this project, a predictive model was built using the Home Credit dataset to identify clients that may face difficulties repaying their loan. Various feature selection techniques were explored, including Recursive Feature Elimination with XGBoost and Linear Discriminant Analysis, and Mutual Information Coefficient. Multiple machine learning models were developed and evaluated, with particular focus on XGBoost and CatBoost. Additionally, Hyperopt was used for hyperparameter tuning to further optimize the models.

## Needs of this project

- Data exploration and descriptive statistics
- Data preprocessing and cleaning
- Feature selection and engineering
- Predictive modeling and model comparison
- Hyperparameter tuning
- Evaluation metric interpretation

## Getting Started

1. Clone this repo (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)).
2. Raw Data is kept [here](https://www.kaggle.com/c/home-credit-default-risk/data) from Kaggle's Home Credit Default Risk competition.
3. Data processing/transformation scripts are being kept in the Jupyter notebooks within this repository.

## Featured Notebooks/Analysis/Deliverables
* [Feature Selection and XGBoost Model Notebook](link)
* [Hyperparameter Tuning and CatBoost Model Notebook](link)
* [Blog Post on Model Interpretation and Business Impact](link)
